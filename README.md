# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

---
Для решения задачи обеспечения процесса разработки в рамках микросервисной архитектуры предлагаю использовать комбинацию следующих инструментов и подходов:

1. Система контроля версий

Git – широко используемая распределённая система контроля версий, поддерживающая ветвление, слияние и управление версиями. Она соответствует требованию облачной системы и поддерживает работу с несколькими репозиториями.

2. Хостинг репозиториев

GitHub/GitLab – оба сервиса поддерживают работу с Git и предоставляют возможности для управления проектами, включая поддержку репозиториев на каждый сервис, а также интеграцию с CI/CD системами.

3. Непрерывная интеграция и доставка (CI/CD)

Jenkins – мощный инструмент для автоматизации сборки, тестирования и развёртывания приложений. Он позволяет запускать сборки по событиям из системы контроля версий (например, при коммите), а также вручную через интерфейс.

Преимущества Jenkins:

* Возможность настройки кастомных шагов при сборке.

* Поддерживает создание шаблонов для различных конфигураций сборок.

* Позволяет безопасно хранить секретные данные (через плагин Credentials).

* Может быть настроен для работы с собственными Docker-образами для сборки проектов.

* Можно развертывать агентов сборки на собственных серверах.

* Поддерживается параллельный запуск нескольких сборок и тестов.

4. Контейнеризация и оркестровка

Docker – для контейнеризации сервисов и среды сборки.

Kubernetes – для оркестрации контейнеров и масштабирования процессов сборки и тестирования.

Пример реализации:

Шаг 1: Настройка репозиториев

Каждый микросервис имеет собственный репозиторий на GitHub/GitLab.

Разработчики работают над кодом локально, используя ветки и pull requests для внесения изменений.

Шаг 2: Интеграция с CI/CD системой

Настроить Jenkins для автоматической сборки проекта после каждого коммита в репозиторий.

В случае необходимости можно настроить ручной запуск сборки с возможностью указания параметров.

Для каждой сборки можно задать индивидуальные настройки (например, параметры окружения, конфигурации).

Шаг 3: Контейнеризация среды сборки

Создать собственные Docker-образы для сборки проектов, которые будут содержать все необходимые инструменты и зависимости.

Эти образы могут быть использованы как внутри Jenkins, так и вне его, что обеспечит стандартизацию среды сборки.

Шаг 4: Оркестровка и масштабирование

Развернуть Kubernetes кластер для выполнения задач сборки и тестирования.

Агенты Jenkins могут работать в контейнерах на этом кластере, обеспечивая возможность параллельной обработки множества сборок.

Шаг 5: Безопасное хранение секретов

Использовать встроенные механизмы Jenkins для хранения паролей и ключей доступа (плагин Credentials). Это позволит избежать утечки конфиденциальных данных.

Шаг 6: Создание шаблонов и кастомных шагов

Определить стандартные шаблоны для различных типов сборок (например, фронтенд, бэкенд, мобильные приложения).

Добавлять кастомные шаги в пайплайны Jenkins для специфических потребностей проекта (например, выполнение специальных проверок качества кода, генерация документации).

Преимущества предложенного подхода:

Гибкость: Возможность адаптировать процесс под конкретные нужды команды благодаря настраиваемым пайплайнам и шаблонам.

Масштабируемость: Использование Kubernetes позволяет легко добавлять новые ресурсы для сборки и тестирования по мере роста нагрузки.

Совместимость: Все компоненты хорошо интегрируются друг с другом, что упрощает внедрение и обслуживание системы.

Безопасность: Механизмы хранения секретов обеспечивают защиту чувствительных данных.

Таким образом, предлагаемое решение полностью удовлетворяет всем указанным требованиям и обеспечивает надёжный и гибкий процесс разработки в условиях микросервисной архитектуры.



## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

---
Для решения задачи сбора и анализа логов в микросервисной архитектуре предлагаю использовать стек технологий ELK (Elasticsearch, Logstash, Kibana) вместе с Filebeat. Этот набор инструментов отвечает всем перечисленным требованиям и является одним из самых популярных решений для централизованного сбора, индексации и анализа логов.

Компоненты решения:

1. Filebeat – агент для сбора логов. Он собирает логи с серверов и отправляет их в центральное хранилище.

* Сбор логов из stdout.

* Минимальные требования к приложению – вывод логов в стандартный поток вывода.

* Гарантированная доставка логов за счёт механизма буферизации и повторных попыток отправки.

2. Logstash – инструмент для агрегации, трансформации и маршрутизации логов перед их отправкой в Elasticsearch.

* Фильтрует и преобразует данные перед загрузкой в Elasticsearch.

* Поддерживает различные входные и выходные плагины, что делает его универсальным инструментом для интеграции с различными источниками и целевыми системами.

3. Elasticsearch – высокопроизводительная поисковая система, предназначенная для индексирования и быстрого поиска больших объёмов данных.

* Центральное хранилище для логов.

* Обеспечивает мощные возможности поиска и фильтрации по записям логов.

4. Kibana – веб-интерфейс для визуализации и анализа данных, хранящихся в Elasticsearch.

* Предоставляет удобный пользовательский интерфейс для разработчиков.

* Позволяет создавать дашборды, выполнять сложные запросы и сохранять результаты поиска.

* Возможность делиться ссылками на сохранённые поиски.

Принципы взаимодействия компонентов:

1. Сбор логов:

* Приложения пишут логи в stdout, где они собираются агентом Filebeat.

* Filebeat обрабатывает логи и отправляет их в Logstash.

2. Агрегация и обработка:
* Logstash принимает логи от Filebeat, выполняет фильтрацию, нормализацию и обогащение данных.
* После обработки логи отправляются в Elasticsearch для индексирования.

3. Индексирование и хранение:

* Elasticsearch индексирует полученные логи, делая их доступными для поиска и анализа.

4. Анализ и визуализация:

* Kibana используется для построения запросов, фильтров и визуальных представлений логов.
* Разработчики могут искать и анализировать логи через веб-интерфейс Kibana.
* Ссылки на сохранённые поиски могут быть переданы другим пользователям для совместного использования.

Преимущества этого решения:

* Гибкость: ELK Stack предоставляет множество возможностей для настройки и адаптации под конкретные потребности.
* Масштабируемость: Elasticsearch способен обрабатывать большие объёмы данных и легко масштабируется горизонтально.
* Удобство использования: Kibana предлагает интуитивно понятный интерфейс для анализа и визуализации логов.
* Безопасность: доступ к данным можно контролировать с помощью ролей и прав пользователей.
* Интеграционные возможности: логично вписывается в экосистему других инструментов DevOps, таких как Prometheus, Grafana и т.д.

Это решение идеально подходит для микросервисной архитектуры, поскольку оно позволяет собирать и анализировать логи из множества источников, обеспечивая централизованное управление и удобный доступ для разработчиков.




## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

---
Для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре я предлагаю использовать комбинацию из следующих инструментов: Prometheus, Node Exporter, cAdvisor, Grafana. Эта связка позволяет собрать метрики со всех хостов и сервисов, визуализировать их и предоставлять удобные средства мониторинга и анализа.

Компоненты решения:

1. Prometheus – это система мониторинга и оповещения с открытым исходным кодом, ориентированная на мониторинг времени выполнения и доступности сервисов.

* Прометей активно используется для мониторинга в микросервисах благодаря своей простоте и эффективности.

* Собирает метрики с помощью метода "pull" (вытягивание метрик с конечных точек).

2. Node Exporter – экспортер метрик для системных показателей хоста (CPU, RAM, дисковое пространство, сеть и др.).

* Node Exporter устанавливается на каждом хосте и предоставляет Prometheus метрики о состоянии ресурсов хоста.

3. cAdvisor – инструмент для экспорта метрик потребления ресурсов контейнерами (Docker, Kubernetes).

* cAdvisor предоставляет детализированную информацию о потреблении ресурсов каждым контейнером, включая CPU, память, сетевой трафик и использование диска.

4. Grafana – платформа для визуализации и анализа метрик, собранных Prometheus.

* Предоставляет мощные возможности для создания панелей мониторинга, графиков и оповещений.

* Поддерживает гибкие запросы и агрегацию информации.

Способы и принципы взаимодействия компонентов:

1. Сбор метрик:

* На каждом хосте устанавливаются Node Exporter и cAdvisor.

* Node Exporter собирает метрики состояния ресурсов хоста (CPU, RAM, HDD, Network) и предоставляет их через HTTP API.

* cAdvisor собирает метрики потребления ресурсов каждым сервисом (контейнером) и также предоставляет их через HTTP API.

* Prometheus периодически обращается к этим экспортерам и собирает метрики, сохраняя их в свою базу данных.

2. Мониторинг и визуализация:

* Grafana подключается к базе данных Prometheus и использует её для построения графиков, дашбордов и оповещений.

* Пользователи могут создавать персонализированные панели мониторинга, настраивая виджеты и графики для отображения нужных метрик.

* Графана позволяет легко агрегировать информацию, создавая сложные запросы и фильтры.

Преимущества данного решения:

* Широкая поддержка: Prometheus, Node Exporter, cAdvisor и Grafana являются популярными инструментами с большим сообществом и обширной документацией.

* Масштабируемость: Prometheus легко масштабируется за счет поддержки федераций и шардинга.

* Гибкость: Grafana позволяет создавать любые виды панелей и отчетов, адаптируя их под разные сценарии использования.

* Интеграция: все эти инструменты хорошо интегрируются между собой и с другими системами мониторинга, такими как Alertmanager для уведомлений.

* Минимальная нагрузка на сервисы: методы сбора метрик не требуют значительных изменений в самих сервисах, что снижает нагрузку на них.

Обоснование выбора:

1. Prometheus выбран потому, что он специально создан для мониторинга распределенных систем и микросервисов. Его архитектура и подход к сбору метрик позволяют эффективно отслеживать состояние большого количества сервисов и хостов.

2. Node Exporter и cAdvisor необходимы для получения детальной информации о состоянии ресурсов хостов и контейнеров соответственно. Они предоставляют широкий спектр метрик, которые важны для мониторинга производительности и здоровья системы.

3. Grafana является мощным инструментом для визуализации и анализа метрик. Благодаря поддержке Prometheus Query Language (PromQL), пользователи могут строить сложные запросы и получать агрегированную информацию, необходимую для принятия решений.
В итоге, данное решение соответствует всем заявленным требованиям и предоставляет надежную инфраструктуру для мониторинга и анализа состояния хостов и сервисов в микросервисной архитектуре.




## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
